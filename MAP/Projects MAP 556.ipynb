{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de7d5a96",
   "metadata": {},
   "source": [
    "#### Projects MAP 556\n",
    "### Monte Carlo methods and stochastic processes\n",
    "##### GNABEYEU MBIADA Emmanuel\n",
    "##### Alioua Imrane \n",
    "\n",
    "## Variance Reduction Applied to Machine Learning for Pricing Bermudan/American Options in High Dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60471de",
   "metadata": {},
   "source": [
    "> we implement here by a backward dynamic programming algorithm, an efficient method to compute the price of multi-asset American options following a Black-Scholes dynamics, based on Machine Learning, Monte Carlo simulations and variance reduction technique. \n",
    "\n",
    "> The backward dynamic programming algorithm considers a finite number of uniformly distributed exercise dates. On these dates, the option value is computed as the maximum between the exercise value and the continuation value, which is obtained by means of Gaussian process regression technique and Monte Carlo simulations. \n",
    "\n",
    "\n",
    "> We will show that such a method performs well for low dimension baskets but it is not accurate for very high dimension baskets. In order to improve the dimension range and then  overcome the\n",
    "problem of the curse of dimensionality, we employ the European option price as a control variate, which allows us to treat very large baskets and moreover to reduce the variance of price estimators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "238d18fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm \n",
    "from scipy.stats import norm as scnorm\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import interact, widgets\n",
    "from scipy.stats import qmc\n",
    "from scipy import linalg \n",
    "import scipy.optimize as opt\n",
    "\n",
    "from sklearn.datasets import make_friedman2\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, DotProduct, WhiteKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8d4ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supressing the warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e78a4212",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1\n",
    "S_i = 100\n",
    "K = 100\n",
    "r = 0.05,\n",
    "neta_i = 0.0 # equal (null) dividend rates ηi = 0.0, \n",
    "neta = 0.0\n",
    "sigma_i = 0.2 # equal volatilities , \n",
    "rho_ij = 0.2 # equal correlations \n",
    "N = 10  # exercise dates. Moreover, we consider P = 250, 500 or 1000 points,\n",
    "M = np.array([10**3, 10**4 or 10**5]) # Monte Carlo simulations \n",
    "Q = 10000  # points for the computation of the European prices with the GPR-EI formula.\n",
    "P_range=np.array([250,500,1000])\n",
    "d_range = [2, 5, 10, 20, 40, 100] # the dimension d, considering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f26037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(sigma_i,d):\n",
    "    # compute sigma\n",
    "    return np.array([sigma_i for _ in range(d)])\n",
    "\n",
    "def sqrtmh(A):\n",
    "    vals, vecs = linalg.eigh(A)\n",
    "    return vecs @ np.diag(np.sqrt(vals)) @ vecs.T.conjugate()\n",
    "\n",
    "def square_root_correlation_matrix(rho,d,sigma_i):\n",
    "    # compute Gamma and it square gamma\n",
    "    Gamma=rho*np.ones(d)+(1-rho)*np.eye(d)\n",
    "    CorrMatrix=(sigma_i**2)*Gamma\n",
    "    return sqrtmh(Gamma),CorrMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b3aff",
   "metadata": {},
   "source": [
    "$\\sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "642eb673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99069011, 0.09626292, 0.09626292],\n",
       "       [0.09626292, 0.99069011, 0.09626292],\n",
       "       [0.09626292, 0.09626292, 0.99069011]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=3\n",
    "sigma_i=0.2\n",
    "rho=0.2\n",
    "Sigma=variance(sigma_i,d)\n",
    "gamma=square_root_correlation_matrix(rho,d,sigma_i)[0]\n",
    "gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88abf94",
   "metadata": {},
   "source": [
    "#### Geometric and Arithmetic Basket Put Options and  Maximum Call Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1028feb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasketOptions:\n",
    "    def __init__(self, Spot , Strike: float ):\n",
    "        self.S = Spot\n",
    "        self.K = Strike\n",
    "        \n",
    "    def __Arithmetic_Basket_Put_Options__(self,S,K):\n",
    "        \"\"\" S: array of side (d,1)\n",
    "        \"\"\"\n",
    "        self.__init__(self, S , K )\n",
    "        return np.maximum(self.K-self.S.mean(),0)\n",
    "    \n",
    "    def Call_Maximum_d_assets_American_option(self,S,K):\n",
    "        \"\"\" S: array of side (d,1)\n",
    "        \"\"\"\n",
    "        self.__init__(self, S , K )\n",
    "        return np.maximum(self.S.max()-self.K,0)\n",
    "    \n",
    "    def Geometric_Basket_Put_Options(self,S,K):\n",
    "        \"\"\" S: array of side (d,1)\n",
    "        \"\"\"\n",
    "        self.__init__(self, S , K )\n",
    "        prod=1\n",
    "        d=self.S.shape[0]\n",
    "        for i in range(d):\n",
    "            prod*=S[i]\n",
    "            u= K-prod**(1/d)\n",
    "        return np.maximum(u,0)\n",
    "\n",
    "    \n",
    "def Geometric_Basket_Put_Options(S,K):\n",
    "    \"\"\" S: array of side (d,1)\n",
    "    \"\"\"\n",
    "    prod=1\n",
    "    d=S.shape[0]\n",
    "    for i in range(d):\n",
    "        prod*=S[i]\n",
    "    u= K-prod**(1/d)\n",
    "    return np.maximum(u,0)\n",
    "\n",
    "def Arithmetic_Basket_Put_Options(S,K):\n",
    "    \"\"\" S: array of side (d,1)\n",
    "    \"\"\"\n",
    "    u= K-S.mean()\n",
    "    return np.maximum(u,0)\n",
    "\n",
    "\n",
    "def Call_Maximum_d_assets_American_option(S,K):\n",
    "    \"\"\" S: array of side (d,1)\n",
    "    \"\"\"\n",
    "    u= S.max()-K\n",
    "    return np.maximum(u,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c9a8453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S=np.array([102,103,204,302])\n",
    "K=100\n",
    "s= Call_Maximum_d_assets_American_option(S,K)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31475e72",
   "metadata": {},
   "source": [
    "#### Kernel function: SquaredExponentialKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c7b7660",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquaredExponentialKernel:\n",
    "    def __init__(self, sigma_f: float = 1, length: float = 1):\n",
    "        self.sigma_f = sigma_f\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, argument_1: np.array, argument_2: np.array) -> float:\n",
    "        return float(self.sigma_f *\n",
    "                     np.exp(-(np.linalg.norm(argument_1 - argument_2)**2) /\n",
    "                            (2 * self.length**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9982cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f86c804e7c0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_lines = np.arange(-10, 10, 0.1)\n",
    "argument_2= 3  # argument_2=(-10, 10, 0.1)\n",
    "kernel = SquaredExponentialKernel(length=1)\n",
    "y_lines=np.array([kernel(x, argument_2) for x in x_lines]).reshape(-1,1)\n",
    "\n",
    "plt.plot(x_lines,y_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777dfd63",
   "metadata": {},
   "source": [
    "### Price of an European Call Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2b216ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bs_function(S0, K, T, sigma, r):\n",
    "    s = S0\n",
    "    k = K*np.exp(-r*T)\n",
    "    v = sigma*sigma*T\n",
    "    base = np.log(s/k)/np.sqrt(v)\n",
    "    dm, dp = (base - 0.5*np.sqrt(v), base + 0.5*np.sqrt(v))\n",
    "    return S0*scnorm.cdf(dp) - k*scnorm.cdf(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "048a61d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=10\n",
    "M=10**2\n",
    "W=np.random.multivariate_normal(np.zeros(d),np.identity(d),size=M)\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086c9d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "333fb947",
   "metadata": {},
   "source": [
    "#### Optimisation of the Log-Likedlihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00bb66",
   "metadata": {},
   "source": [
    ">The minimize() function is shorthand for scipy.optimize.minimize(). This function returns a dictionary of objects including the solution to the optimization problem and whether the problem actually solved. The minimize function has three mandatory arguments, plus a lot of options. You can experiment with the options on the minimize() documentation page. \n",
    "\n",
    ">1. The first argument of the minimize function is the criterion function (crit() in this example) from which the minimize() function will test values of the parameters in searching for the minimum value.\n",
    ">2. The second argument is an initial guess for the values of the parameters that minimize the criterion function crit().\n",
    ">3. The third argument is the tuple of all the objects needed to solve the criterion function in crit()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcad8fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compute_K(X,sigma_f,sigma_l):\n",
    "    a=X.shape[0]\n",
    "    K=np.zeros((a,a))\n",
    "    for i in range(a):\n",
    "        for j in range(a):\n",
    "            K[i,j]= (sigma_f**2) * np.exp(-(np.linalg.norm(X[i] - X[j])**2) / (2 * sigma_l**2))\n",
    "    return K\n",
    "\n",
    "def log_lik_norm(X,y,sigma_f,sigma_l,sigma_p):\n",
    "    K= Compute_K(X,sigma_f,sigma_l) \n",
    "    p=K.shape[0]\n",
    "    A=K + (sigma_p**2)*np.identity(p)\n",
    "    # assert(A.shape==p)\n",
    "    log_lik_val =0.5*(np.log(np.linalg.det(A))+ y.T@(np.linalg.inv(A))@ y)\n",
    "    neg_log_lik_val = -log_lik_val\n",
    "    return neg_log_lik_val\n",
    "\n",
    "def crit(params,X,y): #, *args):\n",
    "    '''\n",
    "    --------------------------------------------------------------------\n",
    "    This function computes the negative of the log likelihood function\n",
    "    given parameters and data. This is the minimization problem version\n",
    "    of the maximum likelihood optimization problem\n",
    "    --------------------------------------------------------------------\n",
    "    INPUTS:\n",
    "    params = (3,) vector, ([sigma_f,sigma_l,sigma_p])\n",
    "    args   = length 2 tuple, (xvals, cutoff)\n",
    "\n",
    "    RETURNS: neg_log_lik_val\n",
    "    --------------------------------------------------------------------\n",
    "    '''\n",
    "    # X,y =args\n",
    "    sigma_f,sigma_l,sigma_p = params\n",
    "    \n",
    "    # y = args\n",
    "\n",
    "    neg_log_lik_val = log_lik_norm(X,y,sigma_f,sigma_l,sigma_p)\n",
    "    \n",
    "    return neg_log_lik_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44e6fb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Example\n",
    "d=2\n",
    "M=10\n",
    "sigma_l_init = np.random.uniform(0, 1)  \n",
    "sigma_f_init=  np.random.uniform(0, 1)\n",
    "sigma_p_init = np.random.uniform(0, 1)\n",
    "params_init = np.array([sigma_f_init,sigma_l_init,sigma_p_init])\n",
    "\n",
    "X=np.random.multivariate_normal(np.zeros(d),np.identity(d),size=M)\n",
    "K=Compute_K(X,sigma_f_init,sigma_l_init)\n",
    "y=np.random.multivariate_normal(np.zeros(K.shape[0]),(K+sigma_p_init**2)*np.identity(K.shape[0]))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02b56bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.677543862597976"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_log_lik_val=crit(params_init,X,y)\n",
    "neg_log_lik_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1481d26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma_f_MLE= 5.342840814228643 sigma_l_MLE= 3.8271056701371333 sigma_p_MLE= 0.0036323981077430985\n"
     ]
    }
   ],
   "source": [
    "sigma_l_init = np.random.uniform(0, 1)  \n",
    "sigma_f_init=  np.random.uniform(0, 1)\n",
    "sigma_p_init = np.random.uniform(0, 1)\n",
    "\n",
    "params_init = np.array([sigma_f_init,sigma_l_init,sigma_p_init])\n",
    "\n",
    "# pts=(X,y)\n",
    "\n",
    "mle_args = (X,y)\n",
    "results = opt.minimize(crit, params_init, args=mle_args)\n",
    "\n",
    "sigma_f_MLE, sigma_l_MLE,sigma_p_MLE  = results.x\n",
    "\n",
    "print('sigma_f_MLE=', sigma_f_MLE, 'sigma_l_MLE=', sigma_l_MLE,'sigma_p_MLE=', sigma_p_MLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c537f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeSigma_lfp(X,y):\n",
    "    # revoir l'initialisation\n",
    "    sigma_l_init = np.random.uniform(0, 1)  \n",
    "    sigma_f_init=  np.random.uniform(0, 1)\n",
    "    sigma_p_init = np.random.uniform(0, 1)\n",
    "    mle_args = (X,y)\n",
    "    results = opt.minimize(crit, params_init, args=mle_args)\n",
    "    sigma_f_MLE, sigma_l_MLE,sigma_p_MLE  = results.x\n",
    "    return sigma_f_MLE, sigma_l_MLE,sigma_p_MLE\n",
    "\n",
    "def GPR_approximation(X,y):\n",
    "    sigma_l, sigma_f,sigma_p=ComputeSigma_lfp(X,y)\n",
    "    kernel = (sigma_f**2)*RBF(sigma_l)\n",
    "    \n",
    "    gpr = GaussianProcessRegressor(kernel=kernel,\n",
    "         random_state=0).fit(X, y)\n",
    "    return gpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bdc7587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.342840814228643, 3.8271056701371333, 0.0036323981077430985)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=ComputeSigma_lfp(X,y)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4552a8d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k1': 0.869**2,\n",
       " 'k2': RBF(length_scale=1e-05),\n",
       " 'k1__constant_value': 0.7543044680596579,\n",
       " 'k1__constant_value_bounds': (1e-05, 100000.0),\n",
       " 'k2__length_scale': 9.999999999999997e-06,\n",
       " 'k2__length_scale_bounds': (1e-05, 100000.0)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_friedman2\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "\n",
    "sigma_f=a[0]\n",
    "sigma_l=a[1]\n",
    "sigma_p=a[2]\n",
    "kernel=(sigma_f**2)*RBF(sigma_l)\n",
    "gpr = GaussianProcessRegressor(kernel=kernel,\n",
    "         random_state=0).fit(X, y)\n",
    "\n",
    "gpr.score(X, y)\n",
    "gpr.predict(X[:2,:], return_std=True)\n",
    "\n",
    "params = gpr.kernel_.get_params()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed4f0267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1e-10,\n",
       " 'copy_X_train': True,\n",
       " 'kernel__k1': 5.34**2,\n",
       " 'kernel__k2': RBF(length_scale=3.83),\n",
       " 'kernel__k1__constant_value': 28.545947966187395,\n",
       " 'kernel__k1__constant_value_bounds': (1e-05, 100000.0),\n",
       " 'kernel__k2__length_scale': 3.8271056701371333,\n",
       " 'kernel__k2__length_scale_bounds': (1e-05, 100000.0),\n",
       " 'kernel': 5.34**2 * RBF(length_scale=3.83),\n",
       " 'n_restarts_optimizer': 0,\n",
       " 'normalize_y': False,\n",
       " 'optimizer': 'fmin_l_bfgs_b',\n",
       " 'random_state': 0}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpr.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aec689",
   "metadata": {},
   "source": [
    "#### Halton sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6a2f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  Halton_sequence_Rd(d,Q):\n",
    "    \"\"\"output: h shape (d,q) \n",
    "    \"\"\"\n",
    "    sampler = qmc.Halton(d=d, scramble=False) # seed=None\n",
    "    sample = sampler.random(n=Q+1)[1:]\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36f8ecef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=3\n",
    "Q=100\n",
    "sample=Halton_sequence_Rd(d,Q)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4712171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99069011, 0.09626292, 0.09626292],\n",
       "       [0.09626292, 0.99069011, 0.09626292],\n",
       "       [0.09626292, 0.09626292, 0.99069011]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S0=np.array([100,100,100])\n",
    "K=100\n",
    "Neta=np.zeros(d)\n",
    "Sigma=variance(sigma_i,d)\n",
    "gamma=square_root_correlation_matrix(rho,d,sigma_i)[0]\n",
    "gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d966139",
   "metadata": {},
   "source": [
    "####  Choice of the set $X^n$\n",
    ">here we use a deterministic space-filling sequence based on the Halton sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "005b24d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "def compute_x_n(S0,r,Neta, Sigma,gamma,tn,P): # For a fixed n\n",
    "    \"\"\"\n",
    "    Compute set x_np for tn.\n",
    "    Args:\n",
    "        S0: spot price\n",
    "        Neta: array of dividend\n",
    "        r:interest rate\n",
    "        Sigma:array of volatilities of assets\n",
    "        gamma : square of the covariance matrix\n",
    "        tn: time\n",
    "        P: Cardinal of the set Xn\n",
    "    Returns: X_n of shape (P,d)\n",
    "    \"\"\"\n",
    "    d=S0.shape[0]\n",
    "    X_n=[]\n",
    "    sample=Halton_sequence_Rd(d,P)\n",
    "    for p in range(P):\n",
    "        hp=sample[p]\n",
    "        # vectorilization over the coordinates d\n",
    "        x=S0 * np.exp(r-Neta-0.5*(Sigma**2)*tn + np.sqrt(tn)*Sigma*gamma@norm.ppf(hp, loc=10, scale=2))\n",
    "        X_n.append(x)\n",
    "    return np.array(X_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eac8d90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-inf, -inf, -inf])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.ppf([0,0,0], loc=10, scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c905ecfb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2958.75883948,  2379.37340741,  1932.74150781],\n",
       "       [ 2193.98017552,  3837.87119157,  2715.02326815],\n",
       "       [ 4390.21567646,  1682.88560643,  3547.68457177],\n",
       "       ...,\n",
       "       [ 3200.14466753,  9024.01596494,  5486.40753954],\n",
       "       [ 6769.11254898,  1149.30641853, 13076.55515153],\n",
       "       [ 1285.2671002 ,  2059.43099468,   685.00676827]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r=0.15\n",
    "Xn=compute_x_n(S0,r,np.zeros(d), Sigma,gamma,tn=2,P=1000)\n",
    "Xn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66938d3a",
   "metadata": {},
   "source": [
    "####  Choice of the set $X^n_p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57e94613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_X_tilde_np(x_np,r,Neta, Sigma,gamma,DeltaT,M): # For a fixed n and a fixed p\n",
    "    \"\"\"\n",
    "    Compute the profit and loss.\n",
    "    \n",
    "    Args:\n",
    "        x_np: shape (d,1)\n",
    "    Returns:\n",
    "       X_tilde_np: shape (M,d)\n",
    "     \n",
    "    \"\"\"\n",
    "    d=x_np.shape[0]\n",
    "    G=np.random.multivariate_normal(np.zeros(d),np.identity(d),size=M)\n",
    "    X_tilde_np=[]\n",
    "    for m in range(M):\n",
    "        x= x_np * np.exp(r-Neta-0.5*(Sigma**2)*DeltaT + np.sqrt(DeltaT)*Sigma*gamma@G[m])\n",
    "        X_tilde_np.append(x)\n",
    "    return np.array(X_tilde_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6096d897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=12\n",
    "Xnp_tilde=compute_X_tilde_np(Xn[p],r,Neta, Sigma,gamma,DeltaT=0.1,M=1000)\n",
    "Xnp_tilde.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3ae3ad",
   "metadata": {},
   "source": [
    "##  The GPR Monte Carlo Metho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6413ca85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N=10\n",
    "times = np.linspace(0, T, N, endpoint=True)\n",
    "times.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92de8c9e",
   "metadata": {},
   "source": [
    ">Let us introduce the GPR Monte Carlo approach. We approximate the price of an American option with the price of a Bermudan option on the same basket. Specifically, let N be the number of time steps and $\\Delta t = \\frac{T}{N}$ the time increment. \n",
    "\n",
    ">The discrete exercise dates are $t_n = n \\Delta t $, as n = 1, . . . , N. If x represents the vector of the underlying prices at the exercise date $t_n$, then the price of the Bermudan option $v^{BM}$ is given by:$ v^{BM}(t_n,x) = max(\\Phi(x), \\mathbb{E}_{t_n,x}[e^{−r∆t}v(t_{n+1}, S_{t_{n+1}})])$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52967967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GPR_MC_Method(func,S0,K,r,Neta, Sigma,gamma,N,T,P,M):\n",
    "    # gamma is the squarre root of Gamma the Correlation Matrix\n",
    "    # we can proceed by a backward computation of v_BM_tilde \n",
    "   \n",
    "    times = np.linspace(0, T, N, endpoint=True)\n",
    "    dt = T/N\n",
    "    # first value n=N\n",
    "    X_N=compute_x_n(S0,r,Neta, Sigma,gamma,T,P) # shape (P,d) ?\n",
    "    v_BM=[]\n",
    "    for p in range(P):\n",
    "        v_BM.append(func(X_N[p],K)) \n",
    "    v_BM=np.array(v_BM) # shape(P,1)\n",
    "    \n",
    "    # second value n=N-1\n",
    "    X_n=compute_x_n(S0,r,Neta, Sigma,gamma,times[N-1],P) # shape (P,d) ?\n",
    "    \n",
    "    v_BM_tilde=[] # the different approximation for each p\n",
    "    for p in range(P):\n",
    "        x_np=X_n[p]\n",
    "        x_tilde_np=compute_X_tilde_np(x_np,r,Neta, Sigma,gamma,dt,M) # equivalent to S_tN (M,d)\n",
    "        v_BM=0 # for the sum of samples via MC\n",
    "        for m in range(M):\n",
    "            v_BM+=func(x_tilde_np[m],K)\n",
    "        v_BM_tilde.append(np.maximum(func(x_np,K),np.exp(-r*dt)*v_BM/M))\n",
    "    v_BM_tilde=np.array(v_BM_tilde)\n",
    "    \n",
    "    # train a GPR\n",
    "    gpr=GPR_approximation(X_n,v_BM_tilde)\n",
    "        \n",
    "    #intermadiate values\n",
    "    for n in range(N-2,0,-1):\n",
    "        X_n=compute_x_n(S0,r,Neta, Sigma,gamma,times[n],P) # (P,d)\n",
    "        \n",
    "        v_BM_tilde=[] # the different approximation for each p\n",
    "        for p in range(P):\n",
    "            x_np=X_n[p]\n",
    "            x_tilde_np=compute_X_tilde_np(x_np,r,Neta, Sigma,gamma,dt,M) # equivalent to Stn+1(M,d)\n",
    "            v_n=gpr.predict(x_tilde_np)\n",
    "            v_BM_tilde.append(np.maximum(func(x_np,K),np.exp(-r*dt)*v_n.mean()))\n",
    "        v_BM_tilde=np.array(v_BM_tilde) #.reshape(-1)\n",
    "        # train a GPR\n",
    "        print(n)\n",
    "        gpr=GPR_approximation(X_n,v_BM_tilde)\n",
    "\n",
    "    # and then initial value:\n",
    "    x_tilde_0=compute_X_tilde_np(S0,r,Neta, Sigma,gamma,dt,M) # shape(M,d)\n",
    "    v_=gpr.predict(x_tilde_0)  \n",
    "    v_BM_tilde_0 = np.maximum(func(S0,K),np.exp(-r*dt)*v_.mean())\n",
    "  \n",
    "    return v_BM_tilde_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "a92b22de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "8\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "7\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "6\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "5\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "4\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "2\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T=2\n",
    "N=10\n",
    "P=250\n",
    "M=100\n",
    "\n",
    "func=Arithmetic_Basket_Put_Options #function.__Arithmetic_Basket_Put_Options__\n",
    "times = np.linspace(0, T, N, endpoint=True)\n",
    "dt = T/N\n",
    "\n",
    "# first value n=N\n",
    "X_N=compute_x_n(S0,r,Neta, Sigma,gamma,T,P) # shape (P,d) ?\n",
    "v_BM_N=[]\n",
    "for p in range(P):\n",
    "    v_BM_N.append(func(X_N[p],K)) \n",
    "v_BM_N=np.array(v_BM_N) # shape(P,1)\n",
    "    \n",
    "# second value n=N-1\n",
    "X_n=compute_x_n(S0,r,Neta, Sigma,gamma,times[N-1],P) # shape (P,d) ?\n",
    "    \n",
    "v_BM_tilde=[] # the different approximation for each p\n",
    "for p in range(P):\n",
    "    x_np=X_n[p]\n",
    "    x_tilde_np=compute_X_tilde_np(x_np,r,Neta, Sigma,gamma,dt,M) # equivalent to S_tN (M,d)\n",
    "    v_BM=0 # for the sum of samples via MC\n",
    "    for m in range(M):\n",
    "        v_BM+=func(x_tilde_np[m],K)\n",
    "    v_BM_tilde.append(np.maximum(func(x_np,K),np.exp(-r*dt)*v_BM/M))\n",
    "v_BM_tilde=np.array(v_BM_tilde)\n",
    "    \n",
    "# train a GPR\n",
    "gpr=GPR_approximation(X_n,v_BM_tilde)\n",
    "#intermadiate values\n",
    "for n in range(N-2,0,-1):\n",
    "    X_n=compute_x_n(S0,r,Neta, Sigma,gamma,times[n],P) # (P,d)\n",
    "        \n",
    "    v_BM_tilde=[] # the different approximation for each p\n",
    "    for p in range(P):\n",
    "        x_np=X_n[p]\n",
    "        x_tilde_np=compute_X_tilde_np(x_np,r,Neta, Sigma,gamma,dt,M) # equivalent to Stn+1(M,d)\n",
    "        v_n=0 # for the sum of samples via MC\n",
    "        v_=gpr.predict(x_tilde_np)\n",
    "        #for m in range(M):\n",
    "        #    a=gpr.predict(x_tilde_np[m].reshape(1, -1))\n",
    "        #    v_n+=a\n",
    "        v_BM_tilde.append(np.maximum(func(x_np,K),np.exp(-r*dt)*v_.mean()))\n",
    "\n",
    "    v_BM_tilde=np.array(v_BM_tilde) #.reshape(-1)\n",
    "    print(v_BM_tilde)\n",
    "    # train a GPR\n",
    "    print(n)\n",
    "    gpr=GPR_approximation(X_n,v_BM_tilde)\n",
    "\n",
    "# and then initial value:\n",
    "x_tilde_0=compute_X_tilde_np(S0,r,Neta, Sigma,gamma,dt,M) # shape(M,d)\n",
    "v_=gpr.predict(x_tilde_0)  \n",
    "v_BM_tilde_0 = np.maximum(func(S0,K),np.exp(-r*dt)*v_.mean())  \n",
    "v_BM_tilde_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "ac381aa9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250,)"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_BM_tilde.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "3ab61f5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPR_MC_Method(Arithmetic_Basket_Put_Options,S0,K,r,Neta, Sigma,gamma,N=10,T=2,P=250,M=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0227c3f",
   "metadata": {},
   "source": [
    "## The GPR Monte Carlo Control Variate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcdf97f",
   "metadata": {},
   "source": [
    ">thod\n",
    "Let us present the GPR Monte Carlo Control Variate method (GPR-MC-CV), that is our proposed algorithm.\n",
    "The control variate technique is commonly used to reduce the variance of Monte Carlo estimators, but it can also give its contribution in American pricing.\n",
    "\n",
    ">Let us consider an American and an European option with the same payoff function Ψ and maturity T , and let $v^{AM}$ , $v^{EU}$ denote their prices respectively. For a fixed time t and underlying stocks x, we define the American-European price gap\n",
    "as: $v(t, x) = v^{AM}(t, x) − v^{EU}(t, x)$, then v (T, x) = 0.\n",
    "\n",
    "> It is straightforward to see that $ v(t, x) = sup_{τ \\in \\mathbb{T}_{t,T}} \\mathbb{E}_{t,x}[e^{−r(τ−t)}Ψ (τ, Sτ )]$ where $T_t$,T stands for the set of all stopping times taking values in $[t, T ]$ and Ψ is defined by $Ψ (t, x) = Ψ (x) − v^{EU}(t, x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5000b124",
   "metadata": {},
   "source": [
    "Let us consider a set $Z = {z^q, q = 1, . . . , Q}$ consisting of Q points in $R^d$ quasi-randomly distributed quasi-randomly distributed\n",
    "according to the law of the vector $ (σ_1W_1^1, . . . , σ_dW_d^d)^T$\n",
    "\n",
    "In particular, we define $z^q_i =\\sqrt{T}σ_iΣ_ih^q$\n",
    "where $Σ_i$ is i-th row of the matrix Σ and is i-th row of the matrix Σ and $h^q$\n",
    "is the q-th point of the Halton sequence in $R^d$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4af480d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to calculate the respective covariance matrices\n",
    "def cov_matrix(x1, x2, cov_function) -> np.array:\n",
    "    return np.array([[cov_function(a, b) for a in x1] for b in x2])\n",
    "\n",
    "def compute_Z(T,Sigma,gamma,Q):\n",
    "    \"\"\" Sigma: (d,1)\n",
    "         Covariance: (d,d)\n",
    "    output: Z shape (d,q) \n",
    "    \"\"\"\n",
    "    Z=[]\n",
    "    h=Halton_sequence_Rd(d,Q)\n",
    "    for q in range(Q):\n",
    "        h_q=h[q]\n",
    "        z=np.sqrt(T)*Sigma*(gamma@norm.ppf(h_q, loc=10, scale=2))\n",
    "        Z.append(Z)\n",
    "    return np.array(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcffcdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=3\n",
    "Q=100\n",
    "Z=compute_Z(T,Sigma,gamma,Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c81f2e",
   "metadata": {},
   "source": [
    "In a nutshell, the main idea is to approximate the function u by training the GPR method on the set Z.\n",
    "> we compute ω using the formular: $ w = (K(X,X) + σ^2_P I_P)^{−1}y$\n",
    "By cholesky decomposition, we will have: $(K(X,X) + σ^2_P I_P)^{−1}=(LL^T)^{−1}=L^{-T}L^{-1}$ and then $ w =L^{-T}L^{-1}y$, if we set $L^{-1}y=m$,  to find w, we just need to solve the equation $L^Tw=y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ec812f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximation_u(func,S0,K,T,r,Neta,Sigma,gamma,Q):\n",
    "    y=[]\n",
    "    Z=compute_Z(T,Sigma,gamma,Q)\n",
    "    for q in range(Q):\n",
    "        z=Z[q]\n",
    "        ST=S0*np.exp((r-Neta-0.5*(Sigma**2))*T+z)\n",
    "        y.append(func(ST,K))\n",
    "    y=np.array(y)\n",
    "    sigma_f_MLE, sigma_l_MLE,sigma_p_MLE= ComputeSigma_lfp(Z,y)\n",
    "    K= Compute_K(Z,sigma_f_MLE,sigma_l_MLE)  \n",
    "    L = np.linalg.cholesky(K + sigma_p_ML*np.eye(Q))\n",
    "    m = np.linalg.solve(L, y)\n",
    "    w=np.linalg.solve(L.T, m)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b212f4c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_Z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m M\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      5\u001b[0m func\u001b[38;5;241m=\u001b[39mArithmetic_Basket_Put_Options\n\u001b[0;32m----> 6\u001b[0m gpr\u001b[38;5;241m=\u001b[39m\u001b[43mapproximation_u\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mS0\u001b[49m\u001b[43m,\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43mSigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36mapproximation_u\u001b[0;34m(func, S0, K, T, r, Neta, Sigma, gamma, Q)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapproximation_u\u001b[39m(func,S0,K,T,r,Neta,Sigma,gamma,Q):\n\u001b[1;32m      2\u001b[0m     y\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m----> 3\u001b[0m     Z\u001b[38;5;241m=\u001b[39m\u001b[43mcompute_Z\u001b[49m(T,Sigma,gamma,Q)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Q):\n\u001b[1;32m      5\u001b[0m         z\u001b[38;5;241m=\u001b[39mZ[q]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_Z' is not defined"
     ]
    }
   ],
   "source": [
    "T=2\n",
    "N=10\n",
    "P=250\n",
    "M=100\n",
    "func=Arithmetic_Basket_Put_Options\n",
    "gpr=approximation_u(func,S0,K,T,r,Neta,Sigma,gamma,Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096c9bd0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9db51223",
   "metadata": {},
   "source": [
    "The value of a call option for a non-dividend-paying underlying stock in terms of the Black–Scholes parameters is:\n",
    "\n",
    " {\\begin{aligned}C(S_{t},t)&=N(d_{1})S_{t}-N(d_{2})Ke^{-r(T-t)}\\\\d_{1}&={\\frac {1}{\\sigma {\\sqrt {T-t}}}}\\left[\\ln \\left({\\frac {S_{t}}{K}}\\right)+\\left(r+{\\frac {\\sigma ^{2}}{2}}\\right)(T-t)\\right]\\\\d_{2}&=d_{1}-\\sigma {\\sqrt {T-t}}\\\\\\end{aligned}}} {\\begin{aligned}C(S_{t},t)&=N(d_{1})S_{t}-N(d_{2})Ke^{-r(T-t)}\\\\d_{1}&={\\frac {1}{\\sigma {\\sqrt {T-t}}}}\\left[\\ln \\left({\\frac {S_{t}}{K}}\\right)+\\left(r+{\\frac {\\sigma ^{2}}{2}}\\right)(T-t)\\right]\\\\d_{2}&=d_{1}-\\sigma {\\sqrt {T-t}}\\\\\\end{aligned}}}\n",
    "The price of a corresponding put option based on put–call parity with discount factor  e^{-r(T-t)}}e^{{-r(T-t)} is:\n",
    "\n",
    " {\\begin{aligned}P(S_{t},t)&=Ke^{-r(T-t)}-S_{t}+C(S_{t},t)\\\\&=N(-d_{2})Ke^{-r(T-t)}-N(-d_{1})S_{t}\\end{aligned}}\\,} {\\begin{aligned}P(S_{t},t)&=Ke^{-r(T-t)}-S_{t}+C(S_{t},t)\\\\&=N(-d_{2})Ke^{-r(T-t)}-N(-d_{1})S_{t}\\end{aligned}}\\,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d830d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pricing_EU_option(w,Q,CovMatrix,r,t,T,d,sigma_f,sigma_l):\n",
    "    sum_=0\n",
    "    for q in range(Q):\n",
    "        sum_+= w[q]*np.exp(-0.5*(z-z_mean).T@np.linalg.inv((T-t)*CovMatrix+(sigma_l**2)*np.eye(d))@(z-z_mean))\n",
    "    \n",
    "    v= (sigma_f**2)*(sigma_l**d)*sum_ / np.linalg.det((T-t)*CovMatrix+(sigma_l**2)*np.eye(d))\n",
    "    v_EU=np.exp(-r*(T-t))*v\n",
    "    return v_EU\n",
    "\n",
    "def phi_tilde(func,t,x,K):\n",
    "    return func(x,K)-pricing_EU_option(w,P,r,t,T,d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da9c011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_GPR(w,X_npm):\n",
    "    \n",
    "    return w@kernel(X_npm)\n",
    "\n",
    "def GPR_MC_CV_algorithm(func,S0,K,r,Neta, Sigma,gamma,N,T,P,M):\n",
    "    # gamma is the squarre root of Gamma the Correlation Matrix\n",
    "    # we can proceed by a backward computation of v_BM_tilde \n",
    "    \n",
    "       times = np.linspace(0, T, N, endpoint=True)\n",
    "    dt = T/N\n",
    "    # first value n=N\n",
    "    X_np= compute_x_np(S0,r,Neta, Sigma,Covariance,tn)\n",
    "    X_tilde_np=compute_X_tilde_np(x_np,r,Neta, Sigma,Covariance,DeltaT,M)\n",
    "    \n",
    "    w=GPR_approximation(X,y)\n",
    "    v_EU=pricing_EU_option(w,P,r,t,T,d) # for each tn ?\n",
    "    \n",
    "    \n",
    "    #Step N-1:  shaping of v^GPR_n\n",
    "    for p in range(P):\n",
    "        y= phi_tilde(func,tN,X[N-1,p])\n",
    "        w=GPR_approximation(X[p],y)\n",
    "    \n",
    "    # second value n=N-1\n",
    "    X_n=compute_x_n(S0,r,Neta, Sigma,gamma,times[N-1],P) # shape (P,d) ?\n",
    "    \n",
    "    v_tilde=[] # the different approximation for each p\n",
    "    \n",
    "    for p in range(P):\n",
    "        x_np=X_n[p]\n",
    "        v_tilde.append(phi_tilde(func,times[N-1],x_np))\n",
    "    v_BM_tilde=np.array(v_BM_tilde)\n",
    "    # train a GPR\n",
    "    gpr=GPR_approximation(X_n,v_BM_tilde)\n",
    "            \n",
    "    for n in range (N-2,0,-1):\n",
    "        #Step n:\n",
    "        X_n=compute_x_n(S0,r,Neta, Sigma,gamma,times[n],P) # (P,d)\n",
    "        v_tilde=[] \n",
    "        for p in range(P):\n",
    "            x_np=X_n[p]\n",
    "            x_tilde_np=compute_X_tilde_np(x_np,r,Neta, Sigma,gamma,dt,M) # equivalent to Stn+1(M,d)\n",
    "            v_n=gpr.predict(x_tilde_np)\n",
    "        \n",
    "            phi_=phi_tilde(func,times[n],x_np)\n",
    "            right=(np.exp(-r*dt)/M) *np.sum(evaluation_GPR(w,x_tilde_np)) @@@\n",
    "            v_tilde.append(np.maximum(phi,right))\n",
    "        \n",
    "        v_tilde=np.array(v_tilde) #.reshape(-1)\n",
    "        # train a GPR\n",
    "        print(n)\n",
    "        gpr=GPR_approximation(X_n,v_tilde)\n",
    "\n",
    "        \n",
    "    #step 0\n",
    "    x_tilde_0=compute_X_tilde_np(S0,r,Neta, Sigma,gamma,dt,M) # shape(M,d)\n",
    "    v_=gpr.predict(x_tilde_0)  \n",
    "    right= (np.exp(-r*dt)/M ) *v_.mean()\n",
    "    v_tilde_0=np.maximun(func(S0,K),right)\n",
    "    \n",
    "    v_BM=v_tilde_0+pricing_EU_option(0,S0)\n",
    "    return v_BM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90e0389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "481fb6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to calculate the respective covariance matrices\n",
    "def cov_matrix(x1, x2, cov_function) -> np.array:\n",
    "    return np.array([[cov_function(a, b) for a in x1] for b in x2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b75434b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1=np.array([9,6,1,5])\n",
    "x2=np.array([2,4,3,7])\n",
    "\n",
    "x1.dot(x1.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e7635a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e7d7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python388jvsc74a57bd032bc4865ff533d9924e3f435c0b7cbf0a5ccc7553dc0d6f60f24e025510084c4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
